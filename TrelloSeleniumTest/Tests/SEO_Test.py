import time
import logging
import pytest
import requests
from collections import Counter
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from TrelloSeleniumTest.Until.untils import login_to_atlassian, navigate_to_trello
from selenium.webdriver.support.wait import WebDriverWait

# Configure Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Setup WebDriver
@pytest.fixture
def driver():
   options = webdriver.ChromeOptions()
   options.add_argument("--start-maximized")
   driver = webdriver.Chrome(options=options)
   yield driver
   driver.quit()

# Region: C√°c h√†m ki·ªÉm tra SEO
def check_title(driver):
   try:
       title = driver.title
       title_length = len(title)
       print(f"üìè ƒê·ªô d√†i ti√™u ƒë·ªÅ: {title_length} k√Ω t·ª±")
       if 30 < title_length < 60:
           print("‚úÖ Title Tag: Passed")
       else:
           print(f"‚ùå Ti√™u ƒë·ªÅ n√™n t·ª´ 30-60 k√Ω t·ª± (Hi·ªán t·∫°i: {title_length})")
   except Exception as e:
       print(f"‚ùå Kh√¥ng t√¨m th·∫•y ti√™u ƒë·ªÅ trang")

def check_meta_description(driver):
   try:
       meta_desc = driver.find_element(By.XPATH, "//meta[@name='description']").get_attribute("content")
       desc_length = len(meta_desc)
       print(f"üìè ƒê·ªô d√†i meta description: {desc_length} k√Ω t·ª±")
       if 50 < desc_length < 160:
           print("‚úÖ Meta Description: Passed")
       else:
           print(f"‚ùå Meta description n√™n t·ª´ 50-160 k√Ω t·ª± (Hi·ªán t·∫°i: {desc_length})")
   except Exception as e:
       print(f"‚ùå Kh√¥ng t√¨m th·∫•y th·∫ª m√¥ t·∫£")

def check_heading_structure(driver):
   print("\n=== KI·ªÇM TRA C·∫§U TR√öC HEADING ===")
   headings = {f'h{i}': driver.find_elements(By.TAG_NAME, f'h{i}') for i in range(1, 7)}

   # Ki·ªÉm tra H1
   h1_count = len(headings['h1'])
   status = "‚úÖ" if h1_count == 1 else "‚ùå"
   print(f"{status} S·ªë H1: {h1_count}")

   # Ph√¢n t√≠ch th·ª© t·ª± heading
   prev_level = 0
   for h_tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
       current_headings = headings[h_tag]
       current_level = int(h_tag[1])
       if current_headings:
           print(f"üîç {h_tag.upper()} ({len(current_headings)}): {[heading.text for heading in current_headings]}")

       for heading in current_headings:
           if current_level - prev_level > 1:
               print(f"‚ùå L·ªói th·ª© t·ª±: {h_tag.upper()} sau H{prev_level}")
           prev_level = current_level

def check_internal_links(driver):
   print("\n=== KI·ªÇM TRA LI√äN K·∫æT N·ªòI B·ªò ===")
   links = driver.find_elements(By.TAG_NAME, "a")
   internal_links = [link.get_attribute("href") for link in links if
                     link.get_attribute("href") and link.get_attribute("href").startswith(driver.current_url)]

   broken_links = []
   for url in internal_links:
       try:
           with requests.head(url, allow_redirects=True) as response:
               if 400 <= response.status_code < 500:
                   broken_links.append(url)
       except Exception as e:
           print(f"‚ùå L·ªói khi ki·ªÉm tra li√™n k·∫øt: {url} - {str(e)}")

   if broken_links:
       print(f"‚ùå Ph√°t hi·ªán {len(broken_links)} li√™n k·∫øt l·ªói 4xx:")
       for link in broken_links:
           print(f"üîó {link}")
   else:
       print("‚úÖ Kh√¥ng c√≥ li√™n k·∫øt n·ªôi b·ªô n√†o b·ªã l·ªói 4xx.")

def check_images_alt(driver):
   print("\n=== KI·ªÇM TRA ·∫¢NH THI·∫æU ALT ===")
   images = driver.find_elements(By.TAG_NAME, "img")
   missing_alt = [img for img in images if not img.get_attribute("alt")]

   if missing_alt:
       print(f"‚ùå Ph√°t hi·ªán {len(missing_alt)} ·∫£nh thi·∫øu alt:")
       for img in missing_alt:
           print(f"üì∑ {img.get_attribute('src')}")
   else:
       print("‚úÖ T·∫•t c·∫£ ·∫£nh ƒë·ªÅu c√≥ thu·ªôc t√≠nh alt h·ª£p l·ªá")

def check_headings(driver):
   """Ki·ªÉm tra v√† li·ªát k√™ c√°c th·∫ª heading (H1, H2, H3, ...) tr√™n trang."""
   try:
       # ========== PH·∫¶N TH√äM M·ªöI ==========
       SEO_STANDARDS = {
           'H1': 70,  # Ti√™u chu·∫©n ƒë·ªô d√†i 2025
           'H2': 80,
           'H3': 100,
           'H4': 120,
           'H5': 120,
           'H6': 120
       }

       headings = driver.find_elements(By.CSS_SELECTOR, 'h1, h2, h3, h4, h5, h6')
       heading_texts = [heading.text for heading in headings]

       # Ki·ªÉm tra v√† li·ªát k√™ th·∫ª H1 trong <noscript>
       noscript_h1 = driver.execute_script(
           "return document.querySelector('noscript') ? document.querySelector('noscript').innerHTML : '';"
       )
       if '<h1>' in noscript_h1:
           start_index = noscript_h1.index('<h1>') + len('<h1>')
           end_index = noscript_h1.index('</h1>')
           noscript_h1_text = noscript_h1[start_index:end_index]
           heading_texts.append(noscript_h1_text)

       if heading_texts:
           print("‚úÖ C√°c th·∫ª heading ph√°t hi·ªán:")
           for heading in headings:
               tag_name = heading.tag_name.upper()
               heading_text = heading.text.strip()

               text_length = len(heading_text)
               length_status = "‚úÖ" if text_length <= SEO_STANDARDS[
                   tag_name] else f"‚ùå V∆Ø·ª¢T {text_length - SEO_STANDARDS[tag_name]} k√Ω t·ª±"

               print(f"{tag_name}: {heading_text} (class: {heading.get_attribute('class')})")
               print(f"   ƒê·ªô d√†i: {text_length}/{SEO_STANDARDS[tag_name]} chars - {length_status}")  # Th√™m d√≤ng n√†y

           if '<h1>' in noscript_h1:
               noscript_h1_text = noscript_h1_text.strip()
               # ========== PH·∫¶N TH√äM M·ªöI ==========
               noscript_length = len(noscript_h1_text)
               noscript_status = "‚úÖ" if noscript_length <= SEO_STANDARDS[
                   'H1'] else f"‚ùå NGUY C∆† PENALTY ({noscript_length} chars)"

               print(f"H1 (trong noscript): {noscript_h1_text}")
               print(f"   ƒê·ªô d√†i: {noscript_length}/{SEO_STANDARDS['H1']} chars - {noscript_status}")  # Th√™m d√≤ng n√†y
       else:
           print("‚ùå Kh√¥ng ph√°t hi·ªán th·∫ª heading n√†o.")

       # Ki·ªÉm tra s·ªë l∆∞·ª£ng H2
       h2_count = len(driver.find_elements(By.CSS_SELECTOR, 'h2'))
       if h2_count == 0:
           print("\n‚ùå Thi·∫øu th·∫ª H2.")
       else:
           print(f"\n‚úÖ Ph√°t hi·ªán {h2_count} th·∫ª H2.")

       # Ki·ªÉm tra th·ª© t·ª± H1 v·ªõi H2
       h1_elements = driver.find_elements(By.TAG_NAME, 'h1')
       if h1_elements:
           h1 = h1_elements[0]
           previous_elements = driver.execute_script('return arguments[0].previousElementSibling;', h1)

           if previous_elements and 'h2' in previous_elements.tag_name.lower():
               print("\n‚úÖ H1 ƒë·ª©ng tr∆∞·ªõc H2.")
           else:
               print("\n‚ùå H1 kh√¥ng ƒë·ª©ng tr∆∞·ªõc H2.")

       print("\nüìä B√°o c√°o t·ªïng quan:")
       total_violations = sum(1 for h in headings if len(h.text.strip()) > SEO_STANDARDS[h.tag_name.upper()])
       print(f"- T·ª∑ l·ªá heading ƒë·∫°t chu·∫©n: {(len(headings) - total_violations) / len(headings) * 100:.1f}%")
       print(f"- Heading d√†i nh·∫•t: {max(len(h.text.strip()) for h in headings)} chars")
       # ===================================

   except Exception as e:
       print(f"\n‚ùå C√≥ l·ªói x·∫£y ra khi ki·ªÉm tra c√°c th·∫ª heading: {str(e)}")

def check_canonical(driver):
   """1. Ki·ªÉm tra th·∫ª Canonical (STT1,32)"""
   try:
       canonical = driver.find_element(By.CSS_SELECTOR, 'link[rel="canonical"]')
       current_url = driver.current_url
       if canonical.get_attribute('href') != current_url:
           print(f"‚ùå Canonical sai: {canonical.get_attribute('href')} vs {current_url}")
       if not canonical.get_attribute('href').startswith('https://'):
           print("‚ùå Canonical d√πng HTTP thay v√¨ HTTPS")
   except:
       print("‚ùå Thi·∫øu th·∫ª canonical")

def check_headers(url):
   """2. Ki·ªÉm tra Security Headers (STT2,21,27)"""
   with requests.get(url) as res:
       headers = res.headers
       missing = []
       if 'X-Frame-Options' not in headers: missing.append('X-Frame-Options')
       if 'Content-Security-Policy' not in headers: missing.append('Content-Security-Policy')
       if 'Referrer-Policy' not in headers: missing.append('Referrer-Policy')
       if missing:
           print(f"‚ùå Thi·∫øu headers b·∫£o m·∫≠t: {', '.join(missing)}")

def run_seo_checks(driver):
   print("\n=== B·∫ÆT ƒê·∫¶U KI·ªÇM TRA SEO ===")

   # C√°c ki·ªÉm tra c∆° b·∫£n
   check_title(driver)
   check_meta_description(driver)

   # Ki·ªÉm tra c·∫•u tr√∫c
   check_heading_structure(driver)

  # Ki·ªÉm tra c√°c y·∫øu t·ªë SEO b·ªï sung
   check_headings(driver)
   check_headers(driver.current_url)
   check_canonical(driver)

   # Ki·ªÉm tra li√™n k·∫øt
   check_internal_links(driver)

   # Ki·ªÉm tra media
   check_images_alt(driver)

   print("=== K·∫æT TH√öC KI·ªÇM TRA SEO ===\n")

# Test case ch√≠nh
def test_seo_checks(driver):
   logging.info("ƒêang ƒëƒÉng nh·∫≠p v√†o Atlassian...")
   login_to_atlassian(driver, "ngotrongnghia8424@gmail.com", "khongcomatkhau4654")
   time.sleep(5)

   print("=== KI·ªÇM TRA SEO TRANG HOME ATLASSIAN ===")
   run_seo_checks(driver)

   logging.info("ƒêang ƒëi·ªÅu h∆∞·ªõng ƒë·∫øn trang Trello Home...")
   navigate_to_trello(driver)
   time.sleep(5)

   print("=== KI·ªÇM TRA SEO TRANG TRELLO HOME ===")
   run_seo_checks(driver)

if __name__ == "__main__":
   pytest.main()
